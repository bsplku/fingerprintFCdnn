{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and modules needed in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "import os\n",
    "# # If you want to sepcify GPU device \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from modules_indiv_identification import init_data_params\n",
    "from modules_indiv_identification import init_train_params\n",
    "from modules_indiv_identification import load_data\n",
    "from modules_indiv_identification import write_info\n",
    "from modules_indiv_identification import init_pretrained_dnn\n",
    "from modules_indiv_identification import init_dnn_last_layer\n",
    "from modules_indiv_identification import init_cost_optimizer\n",
    "from modules_indiv_identification import init_other_variables\n",
    "from modules_indiv_identification import Hoyers_sparsity_control\n",
    "from modules_indiv_identification import get_err\n",
    "from modules_indiv_identification import plot_save_results\n",
    "\n",
    "start_time = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@@@@         Starting         @@@@@@@@@@@@@@@@@@@@@@@@@@\n",
      "@@@@@@@@@@    results_20210908_011832_tgHSP_0.800-0.950    @@@@@@@@@@@\n",
      "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters related to the input data and model architecture\n",
    "directory_open, subject_list, n_subjects, window_length_min, n_samples_run, n_parcels, exclude_parcels, n_units, selected_units, n_hid_layers, n_sp_layers \\\n",
    " = init_data_params(directory_open='./data', subject_list=np.arange(10)+1)\n",
    "\n",
    "# Initialize parameters related to the training and make result directory.\n",
    "final_directory, n_epochs, epoch_step_show, batch_size, lr_init, lr_min, lr_beginanneal, lr_drate, tg_sp_set, beta_max, beta_lr, gamma, layer_activation, optimizer_algorithm, momentum \\\n",
    " = init_train_params(directory_save='./results', n_epochs=100, batch_size=20, lr_init=0.0001, tg_sp_set=[0.8, 0.95], beta_max=[0.00002, 0.0001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject 1 loaded\n",
      "subject 2 loaded\n",
      "subject 3 loaded\n",
      "subject 4 loaded\n",
      "subject 5 loaded\n",
      "subject 6 loaded\n",
      "subject 7 loaded\n",
      "subject 8 loaded\n",
      "subject 9 loaded\n",
      "subject 10 loaded\n"
     ]
    }
   ],
   "source": [
    "# Write a text file about the overall information\n",
    "write_info(final_directory, n_subjects, window_length_min, n_samples_run, n_units, n_epochs, batch_size, lr_init, lr_min, lr_beginanneal, lr_drate, beta_max, beta_lr, optimizer_algorithm)\n",
    "\n",
    "# Load input data of DNN\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test \\\n",
    " = load_data(directory_open, subject_list, window_length_min, n_samples_run, selected_units)\n",
    "\n",
    "# Number of mini-batches in an epoch\n",
    "n_batches = int(np.ceil(np.size(x_train,0)/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /users/hailey/code/03_code/RS_dynamicFC/for_github/modules_indiv_identification.py:264: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/hailey/code/03_code/RS_dynamicFC/for_github/modules_indiv_identification.py:271: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /users/hailey/code/03_code/RS_dynamicFC/for_github/modules_indiv_identification.py:301: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /opt/conda/envs/tf-gpu/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /users/hailey/code/03_code/RS_dynamicFC/for_github/modules_indiv_identification.py:400: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/hailey/code/03_code/RS_dynamicFC/for_github/modules_indiv_identification.py:452: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/hailey/code/03_code/RS_dynamicFC/for_github/modules_indiv_identification.py:452: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /users/hailey/code/03_code/RS_dynamicFC/for_github/modules_indiv_identification.py:467: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, build a DNN with same structure as pretrained model (to restore pretrained Tensorflow variables easily)\n",
    "X, Y, dnn, dnn_bn, dnn_bn_act, unit_vec_split_pre, n_units_pre, is_train = init_pretrained_dnn(n_units, n_hid_layers)\n",
    "\n",
    "# Initialize operations and variables related to training\n",
    "cost, optimizer, Lr, Beta, Gamma, N_batches = init_cost_optimizer(n_units_pre, unit_vec_split_pre, n_hid_layers, n_sp_layers, dnn, Y)\n",
    "\n",
    "# Create an instance to restore variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Next, substitute the last layer and its related variables with a new one for our data\n",
    "Y, dnn, dnn_bn, dnn_bn_act, unit_vec_split = init_dnn_last_layer(n_units, n_hid_layers, dnn, dnn_bn, dnn_bn_act)\n",
    "\n",
    "with tf.name_scope(\"new_train_test\"):\n",
    "    # Initialize training operations and variables again for the updated DNN structure\n",
    "    cost, optimizer, Lr, Beta, Gamma, N_batches = init_cost_optimizer(n_units, unit_vec_split, n_hid_layers, n_sp_layers, dnn, Y)\n",
    "\n",
    "    # Calculate an average error depending on how frequently classified correctly\n",
    "    predict_ans = tf.argmax(dnn_bn_act[-1], 1)\n",
    "    correct_ans = tf.argmax(Y, 1)\n",
    "    error = 1-tf.reduce_mean(tf.cast(tf.equal(predict_ans,correct_ans), tf.float32))\n",
    "\n",
    "# Create lists and arrays to store results obtained during training\n",
    "lr, hsp, beta, beta_vec, plot_hsp, plot_beta, plot_lr, plot_tot_cost, plot_train_err, plot_val_err, plot_test_err \\\n",
    " = init_other_variables(n_subjects, lr_init, n_units, n_sp_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /users/hailey/data/00_data/RS_dynamicFC/04_classification_results/results_DNN/results_DNN_15sec_62835-2000-2000-300_20210501_024446/outer1_selected_(0.800)-(0.950)-(0.000)_L2_(1.0e-8)/result_model.ckpt-2000\n",
      "<epoch 010> tr err: 0.000 /vd err: 0.168 /ts err: 0.123 /HSP: ['0.73', '0.94']\n",
      "<epoch 020> tr err: 0.000 /vd err: 0.165 /ts err: 0.116 /HSP: ['0.73', '0.94']\n",
      "<epoch 030> tr err: 0.000 /vd err: 0.158 /ts err: 0.114 /HSP: ['0.74', '0.94']\n",
      "<epoch 040> tr err: 0.000 /vd err: 0.154 /ts err: 0.112 /HSP: ['0.74', '0.94']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################################################# Start training #################################################\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Tensorflow's operations and tensors can be executed/evaluated in the session\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=False, gpu_options=tf.GPUOptions(allow_growth=True))) as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    # Restore variables of pretrained model\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(\"./pretrained/\"))\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # Shuffle sample order before starting an epoch\n",
    "        tr_ids_shuff = np.arange(np.size(x_train,0), dtype=int)\n",
    "        np.random.shuffle(tr_ids_shuff)\n",
    "\n",
    "        # Learning rate annealing\n",
    "        if lr_beginanneal==0:\n",
    "            lr = lr*1.0\n",
    "        elif epoch+1 >lr_beginanneal:\n",
    "            lr = max(lr_min, (-lr_drate*(epoch+1) +(1+lr_drate*lr_beginanneal))*lr)\n",
    "\n",
    "        tot_cost_epoch = np.float32(0.0)\n",
    "\n",
    "        # Mini-batch based training\n",
    "        for batch in range(n_batches):\n",
    "            if batch<(n_batches-1):\n",
    "                x_batch, y_batch = x_train[tr_ids_shuff[batch*batch_size:(batch+1)*batch_size],:], \\\n",
    "                                   y_train[tr_ids_shuff[batch*batch_size:(batch+1)*batch_size],:]\n",
    "            else:\n",
    "                # for the last batch\n",
    "                x_batch, y_batch = x_train[tr_ids_shuff[batch*batch_size:],:], \\\n",
    "                                   y_train[tr_ids_shuff[batch*batch_size:],:]\n",
    "\n",
    "            tot_cost_batch,_ = sess.run([cost, optimizer],\\\n",
    "                               {Lr:lr, Beta:beta_vec, Gamma:gamma, N_batches:n_batches, is_train:True, X:x_batch, Y:y_batch})\n",
    "\n",
    "            tot_cost_epoch += np.float32(tot_cost_batch)\n",
    "\n",
    "            # Weight sparsity control\n",
    "            for layer in range(n_sp_layers):\n",
    "                w_layer = tf.get_default_graph().get_tensor_by_name(os.path.split(dnn[layer].name)[0]+'/kernel:0')\n",
    "                [hsp[layer], beta[layer]] = Hoyers_sparsity_control(beta_lr[layer], sess.run(w_layer), beta[layer], beta_max[layer], tg_sp_set[layer])\n",
    "\n",
    "            # Vectorized all beta values across layers (e.g., (2, 2000) -> (4000,))\n",
    "            beta_vec = [item for sublist in beta for item in sublist]\n",
    "\n",
    "        # Save the results to plot at a certain epoch\n",
    "        plot_lr = np.hstack([plot_lr, [lr]])\n",
    "        plot_tot_cost = np.hstack([plot_tot_cost, [tot_cost_epoch]])\n",
    "        plot_hsp = [np.vstack([plot_hsp[layer], [np.transpose(hsp[layer])]]) for layer in range(n_sp_layers)]\n",
    "        plot_beta = [np.vstack([plot_beta[layer], [np.transpose(beta[layer])]]) for layer in range(n_sp_layers)]\n",
    "\n",
    "        # Get the classification performance\n",
    "        plot_train_err, plot_val_err, plot_test_err \\\n",
    "            = get_err(sess, hsp, epoch, epoch_step_show, n_subjects, n_samples_run, x_train, y_train, x_valid, y_valid, x_test, y_test, \\\n",
    "                             plot_train_err, plot_val_err, plot_test_err,error, X, Y, is_train)\n",
    "\n",
    "\n",
    "    ################################################# Finish training #################################################\n",
    "\n",
    "    # Discard the zeroth element since it is empty\n",
    "    plot_lr = plot_lr[1:]\n",
    "    plot_tot_cost = plot_tot_cost[1:]\n",
    "    plot_train_err = plot_train_err[:,1:]\n",
    "    plot_val_err = plot_val_err[:,1:]\n",
    "    plot_test_err = plot_test_err[:,1:]\n",
    "    for layer in range(n_sp_layers):\n",
    "        plot_beta[layer] = plot_beta[layer][1:]\n",
    "        plot_hsp[layer] = plot_hsp[layer][1:]\n",
    "\n",
    "    # Plot results and save mat files\n",
    "    plot_save_results(sess, final_directory, tg_sp_set, plot_lr, plot_tot_cost, plot_train_err, plot_val_err, plot_test_err, plot_beta, plot_hsp, lr_init, beta_max, dnn, n_units, n_hid_layers, n_sp_layers)\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "\n",
    "    # Save the final performance and running time in a text file\n",
    "    print('******************************* Final results **********************************')\n",
    "    print('Training finished! It ran for %.1f mins \\n\\n'%((end_time-start_time)/60))\n",
    "    print('=> Final validation & test error rate = {:.3f}'.format(np.mean(plot_val_err[:,-1])),'& {:.3f}'.format(np.mean(plot_test_err[:,-1])))\n",
    "\n",
    "    f = open(final_directory+'/final_info.txt','w')\n",
    "    f.write('Training finished! It ran for %.1f mins \\n\\n'%((end_time-start_time)/60))\n",
    "    f.write('=> Final validation & test error rate = {:.3f}'.format(np.mean(plot_val_err[:,-1]))+' & {:.3f}'.format(np.mean(plot_test_err[:,-1])))\n",
    "    f.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
